# ============================================================
# RAG Advanced Pipeline - Environment Configuration
# ============================================================
# Copy this file to .env and update with your settings
# ============================================================

# ========== LLM Provider ==========
# Options: openai, vllm, ollama
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o
LLM_API_KEY=your-openai-api-key-here
LLM_BASE_URL=
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=2000

# vLLM (GPU) Configuration
# LLM_PROVIDER=vllm
# LLM_BASE_URL=http://localhost:8000/v1
# LLM_MODEL=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
# LLM_API_KEY=  # Optional for vLLM

# Ollama (Local) Configuration
# LLM_PROVIDER=ollama
# LLM_BASE_URL=http://localhost:11434
# LLM_MODEL=llama3.1:8b

# ========== Embedding Provider ==========
# Options: openai, infinity, sentence_transformers
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_API_KEY=your-openai-api-key-here
EMBEDDING_BASE_URL=
EMBEDDING_DIMENSION=1536

# Infinity (GPU) Configuration
# EMBEDDING_PROVIDER=infinity
# EMBEDDING_BASE_URL=http://localhost:7997
# EMBEDDING_MODEL=BAAI/bge-m3
# EMBEDDING_DIMENSION=1024

# SentenceTransformers (Local) Configuration
# EMBEDDING_PROVIDER=sentence_transformers
# EMBEDDING_MODEL=all-MiniLM-L6-v2
# EMBEDDING_DIMENSION=384

# ========== VectorDB Provider ==========
# Options: weaviate, chroma
VECTORDB_PROVIDER=weaviate
VECTORDB_HOST=localhost
VECTORDB_PORT=8080
VECTORDB_API_KEY=
VECTORDB_COLLECTION_NAME=documents

# ChromaDB Configuration
# VECTORDB_PROVIDER=chroma
# VECTORDB_HOST=localhost
# VECTORDB_PORT=8000
# VECTORDB_COLLECTION_NAME=documents

# ========== Chunking Configuration ==========
# Options: semantic, fixed
CHUNKER_TYPE=semantic
CHUNK_SIZE=512
CHUNK_OVERLAP=50
CHUNKER_EMBEDDING_MODEL=  # For semantic chunking, uses EMBEDDING settings if empty

# ========== Retrieval Configuration ==========
RETRIEVAL_TOP_K=5
RETRIEVAL_SCORE_THRESHOLD=0.7

# ========== Logging ==========
LOG_LEVEL=INFO
